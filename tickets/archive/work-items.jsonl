{"archived_at": "2025-10-14T19:58:21Z", "ticket_key": null, "work_item_id": "P3C4-001-002", "module": {"ticket_id": "P3C4-001-002", "title": "RidgeTrainer Implementation", "description": "Implement Ridge regression trainer with alpha=3.0, random_state=42", "module": "src/model2/base_models.py", "dependencies": ["P3C4-001-001"], "input": {"description": "Training data", "schema": "X: DataFrame (N_samples, N_features), y: Series (N_samples,)"}, "output": {"description": "Trained Ridge model", "schema": "Fitted sklearn.linear_model.Ridge object"}, "edge_cases": ["Handle singular matrix: Ridge regularization prevents this", "Empty training set: Raise ValueError", "y contains NaN: sklearn raises, propagate error", "X contains NaN: sklearn raises, propagate error"], "tests": ["test_ridge_trainer_fit: Verify fit on toy data (10 samples, 3 features)", "test_ridge_trainer_predict: Verify predictions match expected shape", "test_ridge_trainer_no_feature_importance: Verify get_feature_importance() returns None", "test_ridge_trainer_determinism: Two fits with same seed produce identical coef_"], "acceptance": "RidgeTrainer trains successfully on synthetic data, predictions deterministic"}}
{"archived_at": "2025-10-15T16:09:10Z", "ticket_key": null, "work_item_id": "P3C4-001-001", "module": {"ticket_id": "P3C4-001-001", "title": "BaseModelTrainer Abstract Interface", "description": "Define abstract base class for model trainers with consistent interface", "module": "src/model2/base_models.py", "dependencies": [], "input": {"description": "Abstract interface definition", "schema": "N/A"}, "output": {"description": "BaseModelTrainer class with abstract methods", "schema": "Python ABC with methods: fit(X, y), predict(X), get_feature_importance(), get_params()"}, "edge_cases": ["Subclasses must implement all abstract methods", "get_feature_importance() returns None for models without feature importance"], "tests": ["test_base_model_trainer_cannot_instantiate: Verify ABC cannot be instantiated directly", "test_base_model_trainer_interface: Verify all required methods exist"], "acceptance": "BaseModelTrainer class exists, cannot be instantiated, defines 4 abstract methods"}}
{"archived_at": "2025-10-15T18:04:36Z", "ticket_key": null, "work_item_id": "P3C4-001-004", "module": {"ticket_id": "P3C4-001-004", "title": "ModelRegistry Configuration", "description": "Create registry for base model configurations", "module": "src/model2/model_registry.py", "dependencies": ["P3C4-001-002", "P3C4-001-003"], "input": {"description": "Model name string", "schema": "model_name: Literal['ridge', 'xgboost']"}, "output": {"description": "Trainer instance and hyperparameters", "schema": "{'trainer': BaseModelTrainer, 'params': dict}"}, "edge_cases": ["Unknown model name: Raise KeyError with available models", "Invalid hyperparameters in config: Raise ValueError with validation message"], "tests": ["test_registry_get_ridge: Verify Ridge config matches specs (alpha=3.0, random_state=42)", "test_registry_get_xgboost: Verify XGBoost config matches specs (all 6 params correct)", "test_registry_unknown_model: Verify KeyError raised for invalid model name", "test_registry_list_models: Verify list_available_models() returns ['ridge', 'xgboost']"], "acceptance": "Registry returns correct trainer and params for both models"}}
{"archived_at": "2025-10-15T18:33:38Z", "ticket_key": null, "work_item_id": "P3C4-001-003", "module": {"ticket_id": "P3C4-001-003", "title": "XGBoostTrainer Implementation", "description": "Implement XGBoost trainer with frozen hyperparameters from specs", "module": "src/model2/base_models.py", "dependencies": ["P3C4-001-001"], "input": {"description": "Training data", "schema": "X: DataFrame (N_samples, N_features), y: Series (N_samples,)"}, "output": {"description": "Trained XGBoost model", "schema": "Fitted xgboost.XGBRegressor object"}, "edge_cases": ["Insufficient samples for tree depth: XGBoost handles gracefully", "Empty training set: Raise ValueError", "y contains NaN: XGBoost raises, propagate error", "Feature names with special chars: Sanitize feature names before training"], "tests": ["test_xgboost_trainer_fit: Verify fit on toy data", "test_xgboost_trainer_predict: Verify predictions match expected shape", "test_xgboost_trainer_feature_importance: Verify get_feature_importance() returns DataFrame with [feature, importance_gain, importance_weight]", "test_xgboost_trainer_determinism: Two fits with same seed produce identical predictions (max diff < 1e-6)"], "acceptance": "XGBoostTrainer trains successfully, extracts feature importance, predictions deterministic"}}
{"archived_at": "2025-10-15T22:54:29Z", "ticket_key": null, "work_item_id": "P3C4-001-005", "module": {"ticket_id": "P3C4-001-005", "title": "OOF Prediction Aggregation", "description": "Aggregate OOF predictions across CV folds into single DataFrame", "module": "src/model2/base_models.py", "dependencies": [], "input": {"description": "List of fold predictions", "schema": "List[Tuple[np.ndarray indices, np.ndarray predictions, int fold_id]]"}, "output": {"description": "Aggregated OOF predictions", "schema": "DataFrame with MultiIndex (instrument, datetime), columns [prediction, fold_id]"}, "edge_cases": ["Duplicate indices across folds: Raise ValueError with overlap info", "Missing indices (incomplete coverage): Log warning with missing count", "Empty fold: Skip fold, log warning", "Prediction NaN: Raise ValueError with fold and index info"], "tests": ["test_oof_aggregation_full_coverage: Verify all indices present exactly once", "test_oof_aggregation_duplicate_indices: Verify ValueError on overlapping folds", "test_oof_aggregation_missing_indices: Verify warning logged for missing indices", "test_oof_aggregation_nan_prediction: Verify ValueError on NaN predictions"], "acceptance": "Aggregation handles 5 folds correctly, detects overlaps and gaps"}}
{"archived_at": "2025-10-16T21:38:19Z", "ticket_key": null, "work_item_id": "P3C4-001-006", "module": {"ticket_id": "P3C4-001-006", "title": "CV Training Loop Orchestrator", "description": "Orchestrate CV training loop for a single model-horizon pair", "module": "src/model2/base_models.py", "dependencies": ["P3C4-001-004", "P3C4-001-005"], "input": {"description": "Training data and CV splitter", "schema": "X: DataFrame, y: Series, cv_splitter: PurgedEmbargoedTimeSeriesSplit, trainer: BaseModelTrainer"}, "output": {"description": "OOF predictions and trained final model", "schema": "{'oof_predictions': DataFrame, 'final_model': BaseModelTrainer, 'cv_scores': List[dict]}"}, "edge_cases": ["CV fold too small: Validate min 100 samples per fold, raise ValueError", "Training fails on fold: Log error, re-raise with fold context", "All predictions in fold are outliers (>1000 bps): Log warning, continue", "Final model training fails: Re-raise with full context"], "tests": ["test_cv_loop_full_pipeline: End-to-end with synthetic data (200 samples, 5 features, 3 folds)", "test_cv_loop_small_fold: Verify ValueError when fold < 100 samples", "test_cv_loop_cv_scores: Verify CV scores logged for all folds (metric='r2')", "test_cv_loop_final_model: Verify final model trained on all data"], "acceptance": "CV loop completes for both models, logs 5 fold scores, returns OOF predictions and final model"}}
{"archived_at": "2025-10-17T01:40:41Z", "ticket_key": null, "work_item_id": "P3C4-001-007", "module": {"ticket_id": "P3C4-001-007", "title": "Feature Importance Extraction and Logging", "description": "Extract XGBoost feature importance and save to parquet", "module": "src/model2/base_models.py", "dependencies": ["P3C4-001-003"], "input": {"description": "Trained XGBoost model", "schema": "model: xgboost.XGBRegressor (fitted)"}, "output": {"description": "Feature importance DataFrame", "schema": "DataFrame with columns [feature, importance_gain, importance_weight], sorted by importance_gain descending"}, "edge_cases": ["No features used (constant target): Return empty DataFrame", "Feature names missing: Use default f0, f1, ... names", "Zero importance for all features: Log warning, return full table"], "tests": ["test_feature_importance_extraction: Verify extraction from fitted XGBoost", "test_feature_importance_sorting: Verify sorted by gain descending", "test_feature_importance_schema: Verify matches FeatureImportance.schema.json", "test_feature_importance_logging: Verify top 20 features logged at INFO level"], "acceptance": "Feature importance extracted, saved to parquet, top 20 logged"}}
{"archived_at": "2025-10-17T21:36:40Z", "ticket_key": null, "work_item_id": "P3C4-001-008", "module": {"ticket_id": "P3C4-001-008", "title": "Model Persistence (Save/Load)", "description": "Save trained models and OOF predictions to disk", "module": "src/model2/base_models.py", "dependencies": ["P3C4-001-006"], "input": {"description": "Trained model and OOF predictions", "schema": "model: BaseModelTrainer, oof_predictions: DataFrame, output_dir: Path"}, "output": {"description": "Files written to disk", "schema": "{output_dir}/{model}_{horizon}.pkl, {output_dir}/oof/{model}_{horizon}.parquet"}, "edge_cases": ["Output directory doesn't exist: Create recursively", "File already exists: Overwrite with warning", "Disk full: Raise OSError with clear message", "Corrupt model object: joblib raises, propagate with context"], "tests": ["test_save_model: Verify model saved to correct path", "test_load_model: Verify loaded model produces identical predictions", "test_save_oof_predictions: Verify OOF parquet written with correct schema", "test_load_oof_predictions: Verify loaded DataFrame matches original"], "acceptance": "Models and OOF predictions saved, can be loaded and produce identical results"}}
{"archived_at": "2025-10-20T00:09:13Z", "ticket_key": null, "work_item_id": "P3C4-001-010", "module": {"ticket_id": "P3C4-001-010", "title": "CV Score Logging and Aggregation", "description": "Log per-fold CV scores and compute aggregate statistics", "module": "src/model2/base_models.py", "dependencies": ["P3C4-001-006"], "input": {"description": "Per-fold predictions and ground truth", "schema": "y_true: np.ndarray, y_pred: np.ndarray, fold_id: int, model_name: str, horizon: str"}, "output": {"description": "CV score dict", "schema": "{'model': str, 'horizon': str, 'fold_id': int, 'r2': float, 'mse': float, 'mae': float}"}, "edge_cases": ["y_true all constant: r2 = NaN, log warning", "y_pred contains NaN: Raise ValueError before scoring", "Metric computation fails: Log error, return None for that metric", "Negative r2 (worse than mean): Log warning, keep value"], "tests": ["test_cv_score_computation: Verify r2, mse, mae computed correctly on toy data", "test_cv_score_constant_target: Verify r2=NaN logged with warning", "test_cv_score_logging_format: Verify logged dict matches CVScores.schema.json", "test_cv_score_aggregation: Verify mean and std computed across folds"], "acceptance": "CV scores computed for all folds, logged in JSON format, aggregated mean/std reported"}}
